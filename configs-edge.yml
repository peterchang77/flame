_id:
  project: flame
  version: null
db:
  query:
    dat-raw: /data/raw/flame/proc/raw/{sid}/dat.hdf5
    lbl-raw: /data/raw/flame/proc/raw/{sid}/lbl.hdf5
    wgt-raw: /data/raw/flame/proc/raw/{sid}/wgt.hdf5
  sform:
    dat-raw: '{root}/proc/raw/{sid}/dat.hdf5'
    lbl-raw: '{root}/proc/raw/{sid}/lbl.hdf5'
    wgt-raw: '{root}/proc/raw/{sid}/wgt.hdf5'
  fdefs: []
  setup:
    prefix: db-edge
    ignore_missing: true
    create_symlinks: false
    create_raw: false
    create_header_from_csv: '{root}/prep/csvs/meta.csv'
    create_stats:
    - name: [shape, vsize, mu, sd, min, max]
      cols: [dat]
      mask: true
    - name: [max, vol]
      cols: [lbl]
    create_cohorts:
    - name: [percentile]
      cols: [lbl-vol]
      bins: 5
    create_valid:
      folds: 5
      group: null
    create_model:
      subsample: false
      max_shape: [1, 128, 128]
      max_ratio: 2
      ignore_vsize: true
client:
  batch:
    fold: -1
    size: 4
    sampling:
      cohort-easy: 0.5
      cohort-hard: 0.5
  specs:
    in_cache: false
    in_memory: true
    xs:
      x:
        dtype: float32
        loads: dat-raw
        shape: [1, 1200, 1200, 1]
      w:
        dtype: float32
        loads: wgt-raw
        shape: [1, 1200, 1200, 1]
      y:
        dtype: float32
        loads: lbl-raw
        shape: [1, 1200, 1200, 1]
      _x-norm_shift:
        dtype: float32
        loads: dat-mu
        shape: [1]
      _x-norm_scale:
        dtype: float32
        loads: dat-sd
        shape: [1]
    load_kwargs:
      verbose: false
xforms:
  patch_size: [1, 128, 128]
  sampling:
    1: 1
    2: 1
  sampling_binarize: false
  norm_lower: -5.0
  norm_upper: 5.0
  rand_aff_2d: true
  rand_aff_sca: [0.8, 1.2]
  rand_aff_rot: [-0.5, 0.5]
  rand_aff_sca_rigid: true
  rand_shift: [-0.1, 0.1]
  rand_scale: [0.9, 1.1]
  y: [y, w]
  m: m
  classes:
    y:
      1: 1
    w:
      1: 1
      2: 2
      3: 3
  mapped:
    m:
    - key: w
      old: {eq: 2}
      new: 1
    - key: w
      old: {eq: 3}
      new: 2
mapped:
  w:
  - key: y
    old: {eq: 1}
    new: 1
  - key: w
    old: {eq: 3}
    $new: [1]
  y:
  - key: w
    old: {eq: 3}
    new: 1
layers:
  norm: layer_norm
  func: leaky_relu
blocks: {}
losses: {}
models:
  kwargs: {}
  backbone:
    name: create_backbone
    configs:
      models:
        pattern:
          name: create_pattern
          names: [encoder, decoder, head]
  head:
    name: create_head
    base: head
    sources:
      strategy: deep
      previous: decoder
    filters: [1]
  training:
    name: create_training
    configs:
      models:
        losses:
          functions:
          - name: foc
            $gamma: [2.0, 2.5, 3.0]
            alpha: 1.0
            y_true: y
            y_pred: head
            w_samp: w
            w_loss: 1.0
          - name: sft
            y_true: y
            y_pred: head
            w_samp: w
            w_loss: 1.0
        metric:
          functions:
          - name: dsc
            y_true: y
            y_pred: head
            w_samp: w
  optimizer:
    name: create_optimizer
    method: Adam
    learning_rate: 0.001
  lr_decay:
    name: create_lr_decay
    decay: 0.99
  callbacks:
    name: create_callbacks
    names: [lr_decay]
params:
  steps: 40000
  steps_per_epoch: 100
  validation_freq: 5
  validation_steps: 100
  save_freq: 10
  save_best_only: []
  save_best_mode: max
  save_paths:
    training: '{output_dir}/{save_format}/{base}'
    backbone: '{output_dir}/{save_format}/{base}/{base}_{offset:03d}'
search:
  file: '{root}/exps/edge/jmodels/csvs/hyper.csv'
  vars:
    gamma:
      keys: models.training.configs.models.losses.functions.0.gamma
      enum:
        2.0: 2.0
        2.5: 2.5
        3.0: 3.0
    wgt:
      keys: mapped.w.1.new
      enum:
        1: 1
output:
  stats:
  - metric: [dsc, h95, 4x4]
    y_true: y
    y_pred: head-0
    w_samp: w
    thresh: [0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95, 0.97, 0.98, 0.99]
    models:
      epochs: [-1]
      graphs: [backbone]
  cohort:
    suffix: last
    column:
      valid: -1
  rename:
    cohort-train: Train
    cohort-valid: Valid
    cohort-whole: Whole
    column-head.*:binary: Foreground
    dsc: Dice Score
    h95: Hausdorff Distance
    sen: Sensitivity
    ppv: Positive Predictive Value
  merged: []
  report: null
