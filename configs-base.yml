_id:
  project: flame
  version: null
db:
  query:
    dat-raw: /data/raw/flame/proc/raw/{sid}/dat.hdf5
    lbl-raw: /data/raw/flame/proc/raw/{sid}/lbl.hdf5
    wgt-raw: /data/raw/flame/proc/raw/{sid}/wgt.hdf5
    dst-raw: /data/raw/flame/proc/raw/{sid}/dst.hdf5
  sform:
    dat-raw: '{root}/proc/raw/{sid}/dat.hdf5'
    lbl-raw: '{root}/proc/raw/{sid}/lbl.hdf5'
    wgt-raw: '{root}/proc/raw/{sid}/wgt.hdf5'
    dst-raw: '{root}/proc/raw/{sid}/dst.hdf5'
  fdefs: []
  setup:
    prefix: db-base
    ignore_missing: false
    create_symlinks: false
    create_raw: false
    create_header_from_csv: '{root}/prep/csvs/meta.csv'
    create_stats:
    - name: [shape, vsize, mu, sd, min, max]
      cols: [dat]
      mask: true
    - name: [max, vol]
      cols: [lbl]
    create_cohorts:
    - name: [percentile]
      cols: [lbl-vol]
      bins: 5
    create_valid:
      folds: 5
      group: null
    create_model:
      subsample: false
      max_shape: [1, 128, 128]
      max_ratio: 2
      ignore_vsize: true
client:
  batch:
    fold: -1
    size: 4
    $sampling: [stratified]
  specs:
    in_cache: false
    in_memory: true
    xs:
      x:
        dtype: float32
        loads: dat-raw
        shape: [1, 1200, 1200, 1]
      y:
        dtype: float32
        loads: lbl-raw
        shape: [1, 1200, 1200, 1]
      w:
        dtype: float32
        loads: wgt-raw
        shape: [1, 1200, 1200, 1]
      _x-norm_shift:
        dtype: float32
        loads: dat-mu
        shape: [1]
      _x-norm_scale:
        dtype: float32
        loads: dat-sd
        shape: [1]
      d:
        dtype: float32
        loads: dst-raw
        shape: [1, 1200, 1200, 1]
    load_kwargs:
      verbose: false
xforms:
  patch_size: [1, 128, 128]
  $sampling: [3-class]
  sampling_binarize: false
  norm_lower: -5.0
  norm_upper: 20.0
  rand_aff_2d: true
  rand_aff_sca: [0.8, 1.2]
  rand_aff_rot: [-0.5, 0.5]
  rand_aff_sca_rigid: true
  rand_shift: [-0.1, 0.1]
  rand_scale: [0.9, 1.1]
  y: [y, w]
  m: m
  classes:
    y:
      1: 1
    w:
      1: 1
      2: 2
  mapped:
    $m: [3-class]
  batch_size: 4
mapped:
  w:
  - key: w
    old: {gt: 0}
    new: 1
  - key: d
    old: {lt: 5, gt: 0}
    $new: [2]
  - key: d
    old: {lt: 0}
    $new: [m1]
  - key: w
    old: {eq: 2}
    $new: [10]
layers:
  norm: layer_norm
  func: leaky_relu
blocks: {}
losses: {}
models:
  kwargs: {}
  backbone:
    name: create_backbone
    configs:
      models:
        pattern:
          name: create_pattern
          names: [encoder, decoder, head]
  head:
    name: create_head
    base: head
    sources:
      strategy: deep
      previous: decoder
    filters: [1]
  training:
    name: create_training
    configs:
      models:
        losses:
          functions:
          - name: foc
            $gamma: [2.0, 2.5, 3.0]
            alpha: 1.0
            y_true: y
            y_pred: head
            w_samp: w
            w_loss: 1.0
          - name: sft
            y_true: y
            y_pred: head
            w_samp: w
            w_loss: 1.0
        metric:
          functions:
          - name: dsc
            y_true: y
            y_pred: head
            w_samp: w
  optimizer:
    name: create_optimizer
    method: Adam
    learning_rate: 0.001
  lr_decay:
    name: create_lr_decay
    decay: 0.99
  callbacks:
    name: create_callbacks
    names: [lr_decay]
params:
  $steps: [40000]
  steps_per_epoch: 100
  validation_freq: 5
  validation_steps: 100
  save_freq: 10
  save_best_only: []
  save_best_mode: max
  save_paths:
    training: '{output_dir}/{save_format}/{base}'
    backbone: '{output_dir}/{save_format}/{base}/{base}_{offset:03d}'
search:
  file: '{root}/exps/base/jmodels/csvs/hyper.csv'
  vars:
    wgt-bg:
      keys: mapped.w.1.new
      enum:
        2: 2
        5: 5
        10: 10
        20: 20
    wgt-fg:
      keys: mapped.w.2.new
      enum:
        e1: 1
        m1:
          mul: -1.0
        m2:
          mul: -2.0
        m5:
          mul: -5.0
    steps:
      keys: params.steps
      enum:
        10000: 10000
        40000: 40000
    gamma:
      keys: models.training.configs.models.losses.functions.0.gamma
      enum:
        2.0: 2.0
        2.5: 2.5
        3.0: 3.0
    sampling-batch:
      keys: client.batch.sampling
      enum:
        percentile:
          cohort-lbl-vol-001-p020: 0.2
          cohort-lbl-vol-001-p040: 0.2
          cohort-lbl-vol-001-p060: 0.2
          cohort-lbl-vol-001-p080: 0.2
          cohort-lbl-vol-001-p100: 0.2
        stratified:
          cohort-easy: 0.5
          cohort-hard: 0.5
    sampling-xforms:
      keys: xforms.sampling
      enum:
        2-class:
          1: 1
          2: 1
        3-class:
          1: 1
          2: 1
          3: 1
    m:
      keys: xforms.mapped.m
      enum:
        2-class:
        - key: w
          old: {eq: 1}
          new: 1
        - key: y
          old: {eq: 1}
          new: 2
        3-class:
        - key: w
          old: {eq: 1}
          new: 1
        - key: y
          old: {eq: 1}
          new: 2
        - key: w
          old: {eq: 2}
          new: 3
    wgt-hard:
      keys: mapped.w.3.new
      enum:
        1: 1
        10: 10
output:
  stats:
  - metric: [dsc, h95, 4x4]
    y_true: y
    y_pred: head-0
    w_samp: w
    thresh: [0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95, 0.97, 0.98, 0.99]
    models:
      epochs: [-1]
      graphs: [backbone]
  cohort:
    suffix: last
    column:
      valid: -1
  rename:
    cohort-train: Train
    cohort-valid: Valid
    cohort-whole: Whole
    column-head.*:binary: Foreground
    dsc: Dice Score
    h95: Hausdorff Distance
    sen: Sensitivity
    ppv: Positive Predictive Value
  merged: []
  report:
  - selected:
      steps: [40000]
      wgt-bg: [2]
      wgt-fg: [m1]
      gamma: [2.0, 2.5, 3.0]
      sampling-batch: [percentile, stratified]
      sampling-xforms: [2-class, 3-class]
      m: [2-class, 3-class]
      wgt-hard: [1, 10]
    subgroup:
      split: [Train]
    ensemble: null
    contents:
    - name: compare
      metric: [dsc, h95, sen, ppv]
      derive: [tp, tn, fp, fn]
      y_true: y
      y_pred: head-0
      format: '{mu:0.2f}, {p50:0.2f} (IQR {p25:0.2f}-{p75:0.2f})'
      choice: sen
      ranked: mu
      sorted: false
      pvalue: ttest_rel
      output: [table, table_diff, violin]
      outdir: '{root}/exps/base/jmodels/outs/raws/000'
      kwargs:
        repeat_cols: [0]
        midrule_cols: [0]
